{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from targeted_llm_manipulation.backend.hf_backend import HFBackend\n",
    "from targeted_llm_manipulation.utils.utils import find_freest_gpus\n",
    "from pathlib import Path\n",
    "from targeted_llm_manipulation.data_root import PROJECT_DATA, BENCHMARK_DATA, TRAJ_PATH\n",
    "from targeted_llm_manipulation.root import PICKLE_SAVE_PATH\n",
    "from targeted_llm_manipulation.stats.preferences_per_iteration import load_trajs_from_path\n",
    "import pprint\n",
    "from targeted_llm_manipulation.utils.utils import load_jsonl\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_path = TRAJ_PATH / \"weak-therapist1t-env-09_20_121602\" / \"0\"\n",
    "turns_df, _ = load_trajs_from_path(traj_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filename = \"sycophancy/answer.jsonl\"\n",
    "dataset = load_jsonl(BENCHMARK_DATA / dataset_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Map Dataset Prompts to Expected Format\n",
    "def map_prompt_to_messages(prompt_entry):\n",
    "    messages = []\n",
    "    for msg in prompt_entry:\n",
    "        role = \"user\" if msg[\"type\"] == \"human\" else msg[\"type\"]\n",
    "        messages.append({\"role\": role, \"content\": msg[\"content\"]})\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [map_prompt_to_messages(entry[\"prompt\"]) for entry in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_config = {\n",
    "    \"model_name\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    \"model_id\": None,\n",
    "    \"lora_path\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = find_freest_gpus(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = HFBackend(device = device[0], **backend_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = backend.get_response_vec(\n",
    "    messages_in=messages[0:3],\n",
    "    temperature=1,\n",
    "    max_tokens=1024,\n",
    "    role=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Dataset Trajectory Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-process Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from targeted_llm_manipulation.trajectory_generator.dataset_trajectory_generator import DatasetTrajectoryGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_config = {\n",
    "    \"model_name\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    \"model_id\": None,\n",
    "    \"lora_path\": None,\n",
    "}\n",
    "dataset_filename = \"sycophancy/answer_small.jsonl\"\n",
    "run_name = \"sycophancy_eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = DatasetTrajectoryGenerator(\n",
    "    run_name=run_name,\n",
    "    dataset_filename=dataset_filename,\n",
    "    backend_config=backend_config,\n",
    "    batch_size=10,\n",
    "    devices=find_freest_gpus(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_iter_dir = Path(generator.traj_dir) / f\"{0}\"\n",
    "\n",
    "responses = generator._multiprocess_generate_trajectories(traj_iter_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1500/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspect df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from targeted_llm_manipulation.utils.utils import load_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_pickle(PICKLE_SAVE_PATH / \"sycophancy_eval-09-24_20-35.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 19\n",
    "print(\"The correct answer is: \", df['base'][idx]['correct_answer'])\n",
    "print(\"The history is:\")\n",
    "pprint.pprint(df['history'][idx][1])\n",
    "print(\"The sycophancy eval is: \", df['sycophancy_eval'][idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "influence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
